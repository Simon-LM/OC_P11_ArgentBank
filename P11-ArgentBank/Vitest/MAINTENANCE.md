<!-- @format -->

# Guide de Maintenance des Tests - Vitest

Ce guide fournit les bonnes pratiques pour maintenir les tests Vitest du projet ArgentBank sur le long terme.

## üîÑ Cycle de vie des tests

### Quand mettre √† jour les tests

- ‚úÖ Lors de changements de l'API d'un composant
- ‚úÖ Lors d'ajout de nouvelles fonctionnalit√©s
- ‚úÖ Lors de correction de bugs
- ‚úÖ Lors de changements de d√©pendances majeures
- ‚úÖ Lors de refactoring

### Signes que les tests ont besoin d'attention

- üö© Tests √©chouant sans modifications du code test√©
- üö© Tests peu fiables (passant/√©chouant al√©atoirement)
- üö© Couverture de code diminuant
- üö© Tests prenant de plus en plus de temps
- üö© Tests contenant trop de mocks ou de complexit√©

## üìà Am√©lioration continue

### Analyse des tests existants

```bash
# Identifier les tests les plus lents
pnpm test -- --reporter=verbose | grep "took"

# Identifier les tests qui √©chouent le plus souvent
pnpm test:watch -- --reporterUpdateInterval=1000
```

### Refactoring de tests

Principes √† suivre :

1. **Clarifier l'intention** : Noms de tests explicites
2. **Simplifier** : R√©duire la complexit√© et les d√©pendances
3. **Consolider** : Regrouper les tests similaires
4. **Isoler** : Assurer l'ind√©pendance des tests

Exemple de refactoring :

```typescript
// Avant
it('test that component works', () => {
  render(<Component prop1="a" prop2="b" prop3="c" prop4="d" />);
  fireEvent.click(screen.getByText('Click'));
  expect(screen.getByText('Result')).toBeInTheDocument();
});

// Apr√®s
it('displays result when button is clicked', () => {
  // Arrangement
  const defaultProps = { prop1: "a", prop2: "b", prop3: "c", prop4: "d" }; // D√©finir defaultProps
  render(<Component {...defaultProps} />);
  const button = screen.getByRole('button', { name: /click/i });

  // Action
  fireEvent.click(button);

  // Assertion
  expect(screen.getByText('Result')).toBeInTheDocument();
});
```

## üêõ R√©solution de probl√®mes courants

### Tests instables (flaky)

Causes fr√©quentes :

- Attentes asynchrones mal g√©r√©es
- D√©pendances entre tests
- Timeouts trop courts
- √âtat global non r√©initialis√©

Solutions :

- Utiliser `waitFor` ou `findBy*` pour les op√©rations asynchrones
- Ajouter `vi.clearAllMocks()` dans `afterEach`
- Augmenter les timeouts pour les tests lents
- Isoler chaque test avec un √©tat initial propre

```typescript
// Correction d'un test asynchrone instable
it('fetches and displays data', async () => {
  // Setup mocks
  const mockFetchData = vi.fn(); // Assurez-vous que mockFetchData est d√©fini
  mockFetchData.mockResolvedValue({ name: 'Test User' });

  render(<UserProfile userId="123" />);

  // Utiliser findBy au lieu de getBy pour attendre le r√©sultat
  await screen.findByText('Test User');
  expect(mockFetchData).toHaveBeenCalledWith('123');
});
```

### Probl√®mes de m√©moire

Si les tests consomment trop de m√©moire :

- Ex√©cuter les tests par groupes plus petits
- Nettoyer les ressources dans `afterEach`
- Surveiller les fuites m√©moire avec `--logHeapUsage`

```bash
# D√©tecter les fuites m√©moire
pnpm test -- --logHeapUsage
```

## üìä Surveillance de la qualit√©

### M√©triques cl√©s

1. **Couverture de code** : Maintenir ou am√©liorer la couverture existante
2. **Temps d'ex√©cution** : Garder les tests rapides (< 30s pour la suite compl√®te)
3. **Fiabilit√©** : 0% de tests instables
4. **Maintenabilit√©** : Code de test lisible et bien structur√©

### Revues r√©guli√®res

Planifier des revues trimestrielles pour :

- Identifier les zones sous-test√©es
- Am√©liorer les tests lents
- Mettre √† jour les mocks obsol√®tes
- Simplifier les tests complexes

## üöÄ Mise √† niveau des d√©pendances

### Strat√©gie de mise √† jour

1. **Pr√©paration** :

   - Capturer les m√©triques actuelles (couverture, vitesse)
   - Ex√©cuter tous les tests pour avoir un baseline

2. **Mise √† jour progressive** :

   - Mettre √† jour une d√©pendance √† la fois
   - Ex√©cuter les tests apr√®s chaque mise √† jour
   - Documenter les changements n√©cessaires

3. **V√©rification** :
   - Comparer les m√©triques avant/apr√®s
   - V√©rifier que tous les tests passent
   - Rechercher les avertissements de d√©pr√©ciation

### D√©pendances critiques

Pour les mises √† jour majeures de ces d√©pendances, v√©rifier la compatibilit√© :

- Vitest
- Testing Library
- React
- Redux Toolkit
- TypeScript

```bash
# V√©rifier les d√©pendances obsol√®tes
pnpm outdated

# Mettre √† jour une d√©pendance sp√©cifique
pnpm update @testing-library/react

# Mettre √† jour toutes les d√©pendances de test
pnpm update -r "@testing-library/*" vitest
```

## üß∞ Outils de diagnostic

### D√©bogage des tests

```bash
# Mode debug avec pause
pnpm test:debug -- Button.test.tsx

# Mode UI
pnpm test:ui

# Mode verbose
pnpm test -- --reporter=verbose
```

### Scripts utiles

Ajouter ces scripts √† `package.json` :

```json
{
	"scripts": {
		"test:find-slow": "pnpm test -- --reporter=verbose | grep -B 1 -A 1 'took.*>100ms'",
		"test:find-flaky": "pnpm test -- --retry=3 --reporter=json | jq '.testResults[] | select(.retry > 0)'",
		"test:by-file": "node scripts/run-tests-by-size.js",
		"test:watch-coverage": "pnpm test:coverage -- --watch"
	}
}
```

## üìù Documentation continue

### Documentation des patterns

Pour chaque nouveau pattern de test :

1. Documenter le probl√®me r√©solu
2. Fournir un exemple minimal
3. Expliquer quand l'utiliser
4. Ajouter √† la documentation appropri√©e

### Biblioth√®que de tests

Maintenir une biblioth√®que d'exemples de tests pour les cas courants :

- Formulaires avec validation
- Requ√™tes API
- Composants contr√¥l√©s vs non-contr√¥l√©s
- Routes prot√©g√©es
- √âtat global avec Redux

## üë• Bonnes pratiques d'√©quipe

### Code reviews

Checklist pour les revues de code de test :

- [ ] Les tests v√©rifient le comportement, pas l'impl√©mentation
- [ ] Les noms de tests sont descriptifs et bas√©s sur le comportement
- [ ] Les arrangements, actions et assertions sont clairement s√©par√©s
- [ ] Les mocks sont minimaux et explicites
- [ ] Les tests sont ind√©pendants les uns des autres

### Sessions de pair-testing

Organiser des sessions o√π deux d√©veloppeurs :

1. √âcrivent des tests ensemble
2. Examinent et am√©liorent des tests existants
3. Partagent des techniques et astuces

## üîÑ Int√©gration continue

### Optimisation du pipeline CI

1. **Mise en cache** :

   - Mettre en cache les d√©pendances node_modules
   - Mettre en cache les r√©sultats de compilation TypeScript

2. **Parall√©lisation** :

   - Diviser les tests en groupes √©quilibr√©s
   - Ex√©cuter les groupes en parall√®le

3. **Fail fast** :
   - √âchouer d√®s le premier test en √©chec
   - Ex√©cuter d'abord les tests les plus susceptibles d'√©chouer

```yaml
# Exemple d'optimisation dans GitHub Actions
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Cache node_modules
        uses: actions/cache@v3
        with:
          path: node_modules
          key: ${{ runner.os }}-modules-${{ hashFiles('pnpm-lock.yaml') }}

      - name: Run critical tests first
        run: pnpm test -- --grep="^(Authentication|User)"

      - name: Run remaining tests
        run: pnpm test -- --exclude="^(Authentication|User)"
```

## üö¶ Maintenance pr√©ventive

### V√©rifications r√©guli√®res

Ex√©cuter ces v√©rifications mensuellement :

```bash
# V√©rifier les tests lents
pnpm test -- --reporter=verbose | grep -B 1 -A 1 "took.*>100ms"

# V√©rifier les avertissements
pnpm test -- 2>&1 | grep -i "warning\|deprecated"

# V√©rifier les tests d√©sactiv√©s
grep -r "it.skip\|describe.skip\|test.skip" --include="*.test.*" src/
```

### Plan de nettoyage

1. **Tests ignor√©s** : Examiner et corriger ou supprimer les tests `.skip`
2. **Tests dupliqu√©s** : Consolider les tests redondants
3. **Tests obsol√®tes** : Supprimer les tests pour les fonctionnalit√©s retir√©es
4. **Mocks inutilis√©s** : Nettoyer les mocks et fixtures non utilis√©s

---

**Navigation** : [Configuration](./CONFIGURATION.md) | [Architecture des tests](./TEST_ARCHITECTURE.md)
